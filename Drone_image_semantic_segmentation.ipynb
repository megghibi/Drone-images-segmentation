{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcESsomVEC4H"
      },
      "source": [
        "#Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook setup**\n",
        "Set the following variables to True or False to run certain cells in the notebook."
      ],
      "metadata": {
        "id": "FpCYRgiU_8yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Explore data\n",
        "print_orig_images = False\n",
        "compute_stats = True\n",
        "\n",
        "#Data Augmentation\n",
        "augment = False\n",
        "use_augmented_data = True\n",
        "load_augmented_data = True\n",
        "a = ('a' if use_augmented_data else '')\n",
        "\n",
        "#Model to use\n",
        "unet = False\n",
        "deeplab = True\n",
        "dl = ('dl' if deeplab else '')\n",
        "\n",
        "#Freeze encoder layers or not\n",
        "freeze_layers = False\n",
        "f = ('f' if freeze_layers else '')\n",
        "\n",
        "#Train model\n",
        "train = False\n",
        "\n",
        "#Create a new dataframe to store models metrics (only set to True once)\n",
        "create_new_df = False\n",
        "\n",
        "#Load trained model from drive (Use if train = False)\n",
        "load_model = True\n",
        "\n",
        "#Print predicted masks\n",
        "plot_predictions = True"
      ],
      "metadata": {
        "id": "dFeWbjJw_7kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUab8LnFZnbK"
      },
      "source": [
        "**Install and import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzkKpjyPtOxj"
      },
      "outputs": [],
      "source": [
        "pip install --quiet -U albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmo58UrnLzJd"
      },
      "outputs": [],
      "source": [
        "pip install --quiet torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqZq14Jmtj4L"
      },
      "outputs": [],
      "source": [
        "pip install --quiet segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nktLL_jaBjyJ"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLojFGHSt9yk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib as mpl\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import albumentations as A\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms.functional as tf\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchmetrics.classification import MulticlassJaccardIndex, MulticlassF1Score, MulticlassAccuracy\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations.augmentations.transforms import Normalize\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import pickle as pkl\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op-aPDpSZvEm"
      },
      "source": [
        "**Check GPU and setup device**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBfJPVbeDM62"
      },
      "outputs": [],
      "source": [
        "# This function checks whether GPU is available. If yes, sets uo device = 'cuda:0' (GPU), otherwise device = 'cpu'\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yIlMwoyZZft"
      },
      "source": [
        "**Mount drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvdaFSV9a4RR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "%ls\n",
        "\n",
        "#Define a directory to export files\n",
        "drive_dir = ''\n",
        "\n",
        "#Directory to save models' data\n",
        "plots_folder = '/Plots/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sipvv3TQ4xg"
      },
      "source": [
        "**Configure environment for Kaggle dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0W9TjxenQ1zY"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = ''\n",
        "os.environ['KAGGLE_KEY'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywdT_30rRd1A"
      },
      "source": [
        "**Download dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ-wXcfERdI3"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d bulentsiyah/semantic-drone-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWvRwXGtSC9F"
      },
      "outputs": [],
      "source": [
        "#Unzip file\n",
        "!unzip -q '/content/semantic-drone-dataset.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Zc2ezPELgx"
      },
      "source": [
        "## Define useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOn-YyWsnpMb"
      },
      "source": [
        "**Functions for data inspection** \\\\\n",
        "This function plots the colors used for plotting of each class in the RGB masks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNH0bDbw1FB5"
      },
      "outputs": [],
      "source": [
        "def print_label_colors():\n",
        "  n = 1\n",
        "  for idx in range(len(labels)):\n",
        "      plt.subplot(6,4,n)\n",
        "      (r,g,b)=labels.iloc[idx].values[1:]\n",
        "      lab = np.array([[[r,g,b],[r,g,b],[r,g,b],[r,g,b]]])\n",
        "      plt.title(f'{idx}: {labels[\"name\"].iloc[idx]}', fontsize = 10)\n",
        "      plt.imshow(lab)\n",
        "      plt.axis('off')\n",
        "\n",
        "      n += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUvu6BY8bPdm"
      },
      "source": [
        "The following functions can be used to inspect the data: \\\\\n",
        "**0.** Computes the minimum and maximum class in all the masks of a dataset.\\\\\n",
        "\n",
        "**1.** Counts the occurrence of all classes in the dataset and the percentage of a each class present in each image.\\\\\n",
        "\n",
        "**2.** Creates a histogram with the distribution of pixels per class in the whole dataset.\\\\\n",
        "\n",
        "**3.** Makes an histogram with the distribution of class percentage in the dataset. \\\\\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEkyfWrUyCRe"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "# 0. This functions counts occurrences of classes in the dataset\n",
        "#Use paths dataframe to only open masks\n",
        "\n",
        "def min_max(paths_df):\n",
        "  #One array to store cumulative frequency of each class\n",
        "  tot_count = np.zeros(23)\n",
        "  #List of arrays to store individual frequencies\n",
        "  count_per_image = np.zeros((len(paths_df), 23))\n",
        "  max = []\n",
        "  min = []\n",
        "  for i in range(len(paths_df)):\n",
        "    mask = np.array(Image.open(paths_df['Mask'].iloc[i]))\n",
        "    max += [np.max(mask)]\n",
        "    min += [np.min(mask)]\n",
        "\n",
        "  min = np.min(min)\n",
        "  max = np.max(max)\n",
        "\n",
        "  return min, max\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 1. This functions counts occurrences of classes in the dataset\n",
        "#Use paths dataframe to only open masks\n",
        "\n",
        "def count_classes(paths_df):\n",
        "  #One array to store cumulative frequency of each class\n",
        "  tot_count = np.zeros(23)\n",
        "  #List of arrays to store individual frequencies\n",
        "  count_per_image = np.zeros((len(paths_df), 23))\n",
        "  max = []\n",
        "  min = []\n",
        "  for i in range(len(paths_df)):\n",
        "    mask = np.array(Image.open(paths_df['Mask'].iloc[i]))\n",
        "    max += [np.max(mask)]\n",
        "    min += [np.min(mask)]\n",
        "\n",
        "    # Count occurrences of each class in the mask\n",
        "    mask_count = np.bincount(mask.flatten(), minlength = 23)   #i = index, 1 = mask\n",
        "    tot_count += mask_count\n",
        "    count_per_class[i] = mask_count\n",
        "\n",
        "  return tot_count, count_per_class\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 2. This function makes a histogram for class frequencies\n",
        "\n",
        "def histogram(count,len, ds_type = ''):\n",
        "  plt.figure(figsize = (10,5))\n",
        "  r = range(23)\n",
        "  width = 0.5\n",
        "\n",
        "  plt.bar(r, count*100/(4000*6000*len), color = 'b',\n",
        "          width = width, edgecolor = 'black',\n",
        "          )\n",
        "  #plt.ylim(0,101)\n",
        "  plt.xlabel(\"Class\", fontsize = 12)\n",
        "  plt.ylabel(\"% of pixels\")\n",
        "  plt.title(f\"% of pixels per class in {ds_type} set\")\n",
        "\n",
        "  plt.xticks(r, labels.name[:-1], rotation = 90)\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# 3. Make three histograms for different classes\n",
        "def class_hist(count,len):\n",
        "  plt.subplots(8,3,figsize = (20,30))\n",
        "\n",
        "  n = 1\n",
        "  #Create one histogram per class\n",
        "  for i in range(23):\n",
        "    plt.subplot(8,3,n)\n",
        "    plt.hist(count[:,i]*100/(4000*6000), bins = 100, range = (-.5,100.5))\n",
        "    plt.xlabel('% pixels')\n",
        "    plt.ylabel('N. images')\n",
        "    plt.ylim(0,len)\n",
        "    plt.xlim(-.5,100.5)\n",
        "    plt.grid(alpha = 0.5)\n",
        "    plt.title(f'Class: {labels.name.iloc[i]}')\n",
        "\n",
        "    n += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aykT0P8egTmL"
      },
      "source": [
        "**Functions for the models** \\\\\n",
        "This function takes as input the output of the model and applies a softmax2d activation function to convert the output to probabilities. For each pixel, the segmentation mask contains the index of the layer with highest probability (which also corresponds to class 0, 1, or 2). The function returns the mask, moved the cpu, as a numpy array and as a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbzQ3QAwggd9"
      },
      "outputs": [],
      "source": [
        "# This function transforms into one channel the output of the model by taking the maximum value per pixel among all channels\n",
        "def output_to_mask(output):\n",
        "  output = output.squeeze(0)\n",
        "  softmax = nn.Softmax2d()\n",
        "  output = softmax(output)\n",
        "  segm = np.argmax(output.cpu().detach().numpy(), axis = 0, keepdims = True)\n",
        "  segm = segm.squeeze(0)\n",
        "  segm_tensor = torch.tensor(segm).to(device)\n",
        "  return segm, segm_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function can be used to define a model. \\\n",
        "Takes as input the encoder name, the architecture to use (UNet or DeepLab), whether to freeze the encoder layers and whether augmented data is being used."
      ],
      "metadata": {
        "id": "AXhEFJkw80d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(encoder, unet = True, freeze = False, use_augmented = use_augmented_data):\n",
        "  if unet:\n",
        "    model = smp.Unet(\n",
        "            encoder_name = encoder,           # choose encoder between mobilenet_v2 or efficientnet-b2\n",
        "            encoder_weights = \"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "            encoder_depth = 5,\n",
        "            in_channels = 3,                  # model input channels (1 for gray-scale images, 3 for RGB)\n",
        "            classes = 23,                     # model output channels (number of classes in your dataset)\n",
        "            activation = 'sigmoid'\n",
        "            )\n",
        "\n",
        "    #Variable for DeepLab model\n",
        "    dl = ''\n",
        "\n",
        "  else:\n",
        "    model = smp.DeepLabV3(\n",
        "          encoder_name = encoder,           # choose encoder\n",
        "          encoder_weights = \"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "          encoder_depth = 3,\n",
        "          in_channels = 3,                  # model input channels (1 for gray-scale images, 3 for RGB)\n",
        "          classes = 23,                     # model output channels (number of classes in your dataset)\n",
        "          activation = 'sigmoid'\n",
        "          )\n",
        "    #Variable for DeepLab model\n",
        "    dl = 'dl'\n",
        "\n",
        "  f = ''\n",
        "  if freeze:\n",
        "    f = 'f'\n",
        "    ## Iteration to freeze first layers and only train the last ones\n",
        "    for key, value in dict(model.named_children()).items():\n",
        "      if \"encoder\" in key:\n",
        "        for param in value.parameters():\n",
        "            param.requires_grad = False\n",
        "      else:\n",
        "        for param in value.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "  a = ''\n",
        "  if use_augmented:\n",
        "    a = 'a'\n",
        "\n",
        "  model_name = encoder + f + dl + a\n",
        "\n",
        "  return model, model_name"
      ],
      "metadata": {
        "id": "eXGlkD98occC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is used to load a trained model."
      ],
      "metadata": {
        "id": "6AIgvJQm9Duj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, model_name):\n",
        "  checkpoint = torch.load(drive_dir + '/Models/'+ 'AerialSegmentation_' + model_name + '_best.pth', map_location = device)\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  model.to(device)\n",
        "\n",
        "  print('Loaded model:', model_name)\n",
        "  return model"
      ],
      "metadata": {
        "id": "rbjGYATboCCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk8vu2EN-oyo"
      },
      "source": [
        "# Prepare dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2W71SQJbG5J"
      },
      "outputs": [],
      "source": [
        "# Define data directories\n",
        "images_dir = '/content/dataset/semantic_drone_dataset/original_images'\n",
        "labels_dir = '/content/dataset/semantic_drone_dataset/label_images_semantic'\n",
        "rgb_labels_dir = '/content/RGB_color_image_masks/RGB_color_image_masks'\n",
        "\n",
        "\n",
        "#Create a dataset containing paths for images, masks and rgb masks\n",
        "paths = {'Image': [], 'Mask': [], 'RGB Mask': []}\n",
        "paths['Image'] += sorted(glob.glob(images_dir + '/*'))\n",
        "paths['Mask'] += sorted(glob.glob(labels_dir + '/*'))\n",
        "paths['RGB Mask'] += sorted(glob.glob(rgb_labels_dir + '/*'))\n",
        "\n",
        "paths = pd.DataFrame(paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhc7g2VPniKn"
      },
      "source": [
        "**Split data into train, test, validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlOYU5QcnX9Z"
      },
      "outputs": [],
      "source": [
        "#First split create test set\n",
        "train_dir, test_dir = train_test_split(paths, test_size = 0.10, random_state = 42, shuffle = True)\n",
        "\n",
        "#Second create train and validation sets\n",
        "train_dir, val_dir = train_test_split(train_dir, test_size = 0.15, random_state = 42, shuffle = True)\n",
        "\n",
        "print('Size of train set: %i' % len(train_dir))\n",
        "print('Size of validation set: %i' % len(val_dir))\n",
        "print('Size of test set: %i' % len(test_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNkv7pOuzqxd"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en4Us6-6YDiH"
      },
      "source": [
        "**Dataset class** \\\\\n",
        "* This class function receives as root directory of images and labels, possible transformations and whether to open the corresponding rgb mask.\n",
        "* It contains a function which returns the length of the dataset and a function which returns the image, mask at a certain index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUv3OzS839FJ"
      },
      "outputs": [],
      "source": [
        "#--Define dataset class--\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  # Initialize dataset class, default transforms = None, default val = False\n",
        "  def __init__(self, root_dir, transforms = None, rgb = False):\n",
        "        #Save all image paths and transforms\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transforms\n",
        "        self.rgb = rgb\n",
        "\n",
        "  def __len__(self):\n",
        "      #Return the number of samples in the dataset\n",
        "      return len(self.root_dir)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      #Open image at index idx following folder paths\n",
        "      img = np.array(Image.open(self.root_dir['Image'].iloc[idx]))\n",
        "      #Open corresponding mask\n",
        "      mask = np.array(Image.open(self.root_dir['Mask'].iloc[idx]))\n",
        "\n",
        "      #If any transformation is passed to the Dataset, apply transformations on image and mask\n",
        "      if self.transform != None:\n",
        "        #First normalize the image (not the mask)\n",
        "        img = normalize(image = img)['image']\n",
        "        #Apply transformations\n",
        "        transf = self.transform(image = img, mask = mask)\n",
        "        img = transf['image']\n",
        "        mask = transf['mask']\n",
        "\n",
        "      if self.rgb:\n",
        "        #Open RGB mask\n",
        "        rgb_mask = np.array(Image.open(self.root_dir['RGB Mask'].iloc[idx]))\n",
        "        return img, mask, rgb_mask\n",
        "\n",
        "      return img, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ-Mqo_3Nsni"
      },
      "source": [
        "# Explore data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGtwRF4LhBaG"
      },
      "source": [
        "**Visualize sample images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seagvjUv0iZm"
      },
      "outputs": [],
      "source": [
        "#Import .csv file with labels and corresponding RGB colors\n",
        "labels = pd.read_csv('class_dict_seg.csv')\n",
        "labels.columns = ['name','r','g','b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeRm3_x91f7f"
      },
      "outputs": [],
      "source": [
        "print_label_colors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYaWnVZXhDpj"
      },
      "outputs": [],
      "source": [
        "#Visualize original images and corresponding RGB masks\n",
        "if print_orig_images:\n",
        "  i = 0\n",
        "  for img, mask, rgb in Dataset(train_dir, rgb = True):\n",
        "\n",
        "    fig = plt.subplots(1,2, figsize = (10,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(rgb)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    if i == 5:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTYHvVZB2poH"
      },
      "source": [
        "**Compute dataset statistics** \\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgmLHuMvS6x7"
      },
      "outputs": [],
      "source": [
        "if compute_stats:\n",
        "  #Find minimum and maximum class in the dataset\n",
        "  min_lab, max_lab = min_max(paths)\n",
        "  print('Lowest class: %i' % min_lab)\n",
        "  print('Highest class: %i' % max_lab)\n",
        "\n",
        "  #Count pixel occurrences and percentages in the datasets\n",
        "  tot_train, img_count_train = count_classes(train_dir)\n",
        "  tot_test, img_count_test = count_classes(test_dir)\n",
        "  tot_val, img_count_val = count_classes(val_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xWeJ_jVmBfj"
      },
      "outputs": [],
      "source": [
        "if compute_stats:\n",
        "  #Visualize distribution of pixels per class in each dataset\n",
        "  histogram(tot_train, len(train_dir), ds_type = 'train')\n",
        "\n",
        "  histogram(tot_test, len(test_dir), ds_type = 'test')\n",
        "\n",
        "  histogram(tot_val, len(val_dir), ds_type = 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJFqBM9XmFMk"
      },
      "outputs": [],
      "source": [
        "if compute_stats:\n",
        "  #Visualize the distribution of percentage of each class in the dataset\n",
        "  class_hist(img_count_train, len(test_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHK5anZzoBr"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA9jzr2oVCBg"
      },
      "source": [
        "ðŸ’€ **Dangerous function: do not set to 'True'** ðŸ’€ \\\\\n",
        "\n",
        "* When ext_augment = True, this function will create a new training set with\n",
        "augmented images.\n",
        "* Seven augmentations are applied to enlargen the dataset. The first transformations are geometric and are applied to both image and mask; the second set of transformations are color-related so they should be applied only to images. \\\\\n",
        "* In this function, augmented images are saved in the original images folder. \\\\\n",
        "\n",
        "ðŸ•“ Estimated running time is 1 hour and 45 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLN0pxM1Fxl3"
      },
      "outputs": [],
      "source": [
        "if augment:\n",
        "  n = 1\n",
        "\n",
        "  #List of classes to augment excluding paved areas and grass\n",
        "  classes_to_augment = np.delete(labels_above_10, [1,3])\n",
        "\n",
        "  #7 transformations to apply to images\n",
        "  #List of geometric transformations to apply to images and masks\n",
        "  transforms_all = A.Compose([A.Compose([A.RandomCrop(width= 5400, height= 3600, p = 1),\n",
        "                               A.HorizontalFlip(p=0.5),\n",
        "                               A.VerticalFlip(p=0.5)], additional_targets = {'mask1': 'mask', 'mask2': 'image'}),\n",
        "                    A.Compose([A.HorizontalFlip(p=1),\n",
        "                               A.VerticalFlip(p=1)], additional_targets = {'mask1': 'mask', 'mask2': 'image'}),\n",
        "                    A.Compose(A.VerticalFlip(p=1), additional_targets = {'mask1': 'mask', 'mask2': 'image'})])\n",
        "\n",
        "  #List of color transformations to apply to images\n",
        "  transforms_img = A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.5, p =1),\n",
        "                              A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=20, val_shift_limit = 10, p =1),\n",
        "                              A.GaussianBlur(blur_limit = (9,19), p =1),\n",
        "                              A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.5, p =1),\n",
        "                                         A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=20, val_shift_limit = 10, p =1),\n",
        "                                         A.GaussianBlur(blur_limit = (9,19), p =1)])])\n",
        "\n",
        "  #Source directory where training images to be augmented are found\n",
        "  to_augment = Dataset(train_dir, rgb = True)\n",
        "\n",
        "  #Create local directory to store new data\n",
        "  os.mkdir(os.path.join('/content/augmented_data/'))\n",
        "  os.mkdir('/content/augmented_data/images')\n",
        "  os.mkdir('/content/augmented_data/masks')\n",
        "  os.mkdir('/content/augmented_data/rgb_masks')\n",
        "\n",
        "  #progress bar\n",
        "  tqdm_images = tqdm_notebook(total = to_augment.__len__(), desc ='Augmented')\n",
        "\n",
        "  for idx in range(len(to_augment)):\n",
        "\n",
        "    #Open image and masks\n",
        "    image, mask, rgb_mask = to_augment[idx]\n",
        "    #Which classes are present in the image\n",
        "    classes_mask = np.unique(mask)\n",
        "\n",
        "    #Apply augmentations if any of the classes to augment is present in the image\n",
        "    if any(item in classes_to_augment for item in classes_mask):\n",
        "      for t in transforms_all:\n",
        "        #Apply geometric transformations\n",
        "        t = transforms_all(image = image, mask1 = mask, mask2 = rgb_mask)\n",
        "        img = tf.to_pil_image(t['image'])\n",
        "        msk = tf.to_pil_image(t['mask1'])\n",
        "        rgb_msk = tf.to_pil_image(t['mask2'])\n",
        "        img.save(f'/content/augmented_data/images/{n}.jpg')\n",
        "        msk.save(f'/content/augmented_data/masks/{n}.png')\n",
        "        rgb_msk.save(f'/content/augmented_data/rgb_masks/{n}.png')\n",
        "\n",
        "        n += 1\n",
        "\n",
        "      mask = Image.fromarray(mask)\n",
        "      rgb_mask = Image.fromarray(rgb_mask)\n",
        "      for t in transforms_img:\n",
        "        #Apply color transformations\n",
        "        t = transforms_img(image = image)\n",
        "        img = tf.to_pil_image(t['image'])\n",
        "        img.save(f'/content/augmented_data/images/{n}.jpg')\n",
        "        mask.save(f'/content/augmented_data/masks/{n}.png')\n",
        "        rgb_mask.save(f'/content/augmented_data/rgb_masks/{n}.png')\n",
        "\n",
        "        n += 1\n",
        "\n",
        "    tqdm_images.update(1)\n",
        "\n",
        "  tqdm_images.close()\n",
        "\n",
        "  #Save externally zip file with augmented data\n",
        "  shutil.make_archive(f'{drive_dir}/augmented_data', 'zip', '/content/augmented_data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hEEmbfjr6Uu"
      },
      "source": [
        "**Download and add augmented data to train set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK8vScZNsUnX"
      },
      "outputs": [],
      "source": [
        "if use_augmented_data:\n",
        "  if load_augmented_data:\n",
        "    !gdown '1jZyemsqNhfZVH-FgD28-1qhi3H5AhQOH'\n",
        "    !unzip -q '/content/augmented_data.zip' -d '/content/augmented_data/'\n",
        "\n",
        "  augm_images_dir = '/content/augmented_data/images'\n",
        "  augm_labels_dir = '/content/augmented_data/masks'\n",
        "  augm_rgb_labels_dir = '/content/augmented_data/rgb_masks'\n",
        "\n",
        "  #Extract paths of augmented images and masks and put everything in a dataframe\n",
        "  augm_paths = {'Image': [], 'Mask': [], 'RGB Mask': []}\n",
        "  augm_paths['Image'] += sorted(glob.glob(augm_images_dir + '/*'))\n",
        "  augm_paths['Mask'] += sorted(glob.glob(augm_labels_dir + '/*'))\n",
        "  augm_paths['RGB Mask'] += sorted(glob.glob(augm_rgb_labels_dir + '/*'))\n",
        "  augm_paths = pd.DataFrame(augm_paths)\n",
        "\n",
        "  #Add augmented data paths to the train paths\n",
        "  train_dir = pd.concat([train_dir, augm_paths])\n",
        "  train_dir = train_dir.sample(frac = 1, random_state = 42, axis = 0, ignore_index = True)\n",
        "  print('New size of training set: %i' % len(train_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UOLX-U2r4Ow"
      },
      "outputs": [],
      "source": [
        "#Display class distribution in augmented train set\n",
        "if use_augmented_data:\n",
        "  if compute_stats:\n",
        "    tot_augm, img_count_augm = count_classes(train_dir)\n",
        "\n",
        "    histogram(tot_augm, len(train_dir), ds_type = 'augmented train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEq7pw6nlajs"
      },
      "source": [
        "# UNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXF_TNUv5zf5"
      },
      "source": [
        "**Define segmentation model** \\\\\n",
        "This function defines the segmentation model by using the smp library where:\n",
        "* encoder is pretrained MobileNet V2 or EfficientNet B2\n",
        "* encoder used pretrained weights on ImageNet\n",
        "* output classes of the net is 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nyKtjV2OFq-"
      },
      "outputs": [],
      "source": [
        "# Define pre-trained classification models to use as encoders\n",
        "encoder1 = \"mobilenet_v2\"\n",
        "encoder2 = \"efficientnet-b2\"\n",
        "\n",
        "encoder = encoder1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE0B9Plrlby1"
      },
      "outputs": [],
      "source": [
        "#Define the model to use\n",
        "model, model_name = define_model(encoder, unet = True, freeze = False)\n",
        "\n",
        "# Net is moved to device (can be cpu or gpu/cuda)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GD7PhwVfXT2"
      },
      "source": [
        "# Dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4lCewE9wP0n"
      },
      "source": [
        "**Define transformations** \\\\\n",
        "Normalization is defined separately because it is only applied to the image and not to the mask."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--Transformations--\n",
        "#This function returns a transformation based on the encoder specified\n",
        "def transform_resize(encoder):\n",
        "  if encoder == encoder1:\n",
        "    # Resized to 224x224 pixels and converted to tensors for MobileNet\n",
        "    transform = A.Compose([\n",
        "                            A.Resize(224, 224, interpolation = cv2.INTER_NEAREST),\n",
        "                            ToTensorV2()\n",
        "                            ],is_check_shapes=False)\n",
        "\n",
        "  else:\n",
        "    # Resized to 288x288 pixels and converted to tensors for EfficientNet\n",
        "    transform = A.Compose([\n",
        "                            A.Resize(288, 288, interpolation = cv2.INTER_NEAREST),\n",
        "                            ToTensorV2()\n",
        "                            ],is_check_shapes=False)\n",
        "\n",
        "  return transform"
      ],
      "metadata": {
        "id": "eIJMJ-jMDcZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSO_CO2__okA"
      },
      "outputs": [],
      "source": [
        "#Assign transformation\n",
        "transform = transform_resize(encoder)\n",
        "\n",
        "#--Normalize--\n",
        "# Data is normalized for the pretrained model\n",
        "normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datasets**"
      ],
      "metadata": {
        "id": "ehvZcpoYCwNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gCbn86UVJPQ"
      },
      "outputs": [],
      "source": [
        "#Import training, testing and validation datasets to be used for training the model (apply transformations)\n",
        "trainset = Dataset(train_dir, transforms = transform, rgb = False)\n",
        "valset = Dataset(val_dir, transforms = transform, rgb = False)\n",
        "testset = Dataset(test_dir, transforms = transform, rgb = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3-L0vzdar8x"
      },
      "source": [
        "**Create dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf4D6pUpYtE2"
      },
      "outputs": [],
      "source": [
        "#--Create dataloaders--\n",
        "batch_size = 32\n",
        "\n",
        "trainloader = DataLoader(trainset,\n",
        "                         batch_size = batch_size,\n",
        "                         shuffle = True,\n",
        "                         drop_last = True,\n",
        "                         num_workers = 0)\n",
        "testloader = DataLoader(testset,\n",
        "                        batch_size = 1,\n",
        "                        shuffle = False,\n",
        "                        drop_last = False,\n",
        "                        num_workers = 0)\n",
        "valloader = DataLoader(valset,\n",
        "                        batch_size = 1,\n",
        "                        shuffle = False,\n",
        "                        drop_last = False,\n",
        "                        num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBBqbo7nlhd5"
      },
      "source": [
        "# Train and evaluate model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J42b5Bvssre"
      },
      "source": [
        "**Define function to validate the model** \\\\\n",
        "This function is used to validate the model by computing micro and macro IoU score and Dice score for segmentation image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRhCLi0VH4wO"
      },
      "outputs": [],
      "source": [
        "# Create validation routine\n",
        "\n",
        "def validate(net, valloader, device, per_class = False):\n",
        "\n",
        "    # Get final scores for micro and macro Dice and IoU scores\n",
        "    iou_score_micro = MulticlassJaccardIndex(num_classes= 23, average = 'micro')\n",
        "    dice_score_micro = MulticlassF1Score(num_classes= 23, average = 'micro')\n",
        "\n",
        "    iou_score_macro = MulticlassJaccardIndex(num_classes= 23, average = 'macro')\n",
        "    dice_score_macro = MulticlassF1Score(num_classes= 23, average = 'macro')\n",
        "\n",
        "    # Move metrics to device\n",
        "    iou_score_micro = iou_score_micro.to(device)\n",
        "    dice_score_micro = dice_score_micro.to(device)\n",
        "\n",
        "    iou_score_macro = iou_score_macro.to(device)\n",
        "    dice_score_macro = dice_score_macro.to(device)\n",
        "\n",
        "    #Compute Micro and Macro Dice and IoU scores per class\n",
        "    if per_class:\n",
        "      iou_score_c = MulticlassJaccardIndex(num_classes= 23, average = None)\n",
        "      dice_score_c = MulticlassF1Score(num_classes= 23, average = None)\n",
        "\n",
        "      iou_score_c = iou_score_c.to(device)\n",
        "      dice_score_c = dice_score_c.to(device)\n",
        "\n",
        "    # Set network in eval mode\n",
        "    net.eval()\n",
        "\n",
        "    n=0\n",
        "\n",
        "    tqdm_val = tqdm_notebook(total= len(valloader), desc='Validation progress', unit='Image')\n",
        "\n",
        "    # At the end of epoch, validate model\n",
        "    for inp, mask in valloader:\n",
        "\n",
        "        # Move batch to gpu\n",
        "        inp = inp.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        # Get output mask\n",
        "        with torch.no_grad():\n",
        "            outmask = net(inp)\n",
        "\n",
        "        # Create a segmentation mask as numpy array and one as tensor\n",
        "        segm_mask, segm_mask_tensor = output_to_mask(outmask)\n",
        "\n",
        "\n",
        "        # Update metrics for each item\n",
        "        iou_score_micro.update(segm_mask_tensor, mask.squeeze(0))\n",
        "        dice_score_micro.update(segm_mask_tensor, mask.squeeze(0))\n",
        "        iou_score_macro.update(segm_mask_tensor, mask.squeeze(0))\n",
        "        dice_score_macro.update(segm_mask_tensor, mask.squeeze(0))\n",
        "\n",
        "        if per_class:\n",
        "          iou_score_c.update(segm_mask_tensor, mask.squeeze(0))\n",
        "          dice_score_c.update(segm_mask_tensor, mask.squeeze(0))\n",
        "\n",
        "        tqdm_val.update(1)\n",
        "        n += 1\n",
        "\n",
        "    # Compute metrics for segmentation tensor vs. original mask\n",
        "    iou_score_micro = iou_score_micro.compute().cpu().numpy()\n",
        "    dice_score_micro = dice_score_micro.compute().cpu().numpy()\n",
        "    iou_score_macro = iou_score_macro.compute().cpu().numpy()\n",
        "    dice_score_macro = dice_score_macro.compute().cpu().numpy()\n",
        "\n",
        "    if per_class:\n",
        "      iou_score_c = iou_score_c.compute().cpu().numpy()\n",
        "      dice_score_c = dice_score_c.compute().cpu().numpy()\n",
        "      return iou_score_micro, dice_score_micro, iou_score_macro, dice_score_macro, iou_score_c, dice_score_c\n",
        "\n",
        "    # set network in training mode\n",
        "    net.train()\n",
        "\n",
        "    return iou_score_micro, dice_score_micro, iou_score_macro, dice_score_macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XdE1B6US-yU"
      },
      "outputs": [],
      "source": [
        "#This function saves externally the validation scores, loss and current epoch at the end of each training-validation epoch\n",
        "#Takes as input\n",
        "#par_dir = parent directory\n",
        "#exp_name = name of the experiment\n",
        "\n",
        "def save_data(par_dir, exp_name):\n",
        "  model_dict = {'dice_micro': micro_dice_list,\n",
        "                'dice_macro': macro_dice_list,\n",
        "                'iou_micro': micro_iou_list,\n",
        "                'iou_macro': macro_iou_list,\n",
        "                'loss': loss_list,\n",
        "                'epochs': cur_epoch-1}\n",
        "\n",
        "  for key in model_dict.keys():\n",
        "    if key != 'epochs':\n",
        "      elem = model_dict[key]\n",
        "      for i in range(len(elem)):\n",
        "        if torch.is_tensor(elem[i]):\n",
        "          elem[i] = elem[i].cpu().numpy()\n",
        "\n",
        "  with open(drive_dir + par_dir + exp_name +'_data.pkl', 'wb') as f:\n",
        "    pkl.dump(model_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXCSKRFSswqY"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xKG2bMltAwL"
      },
      "source": [
        "###**Setup tensorboard**\n",
        "* Define name of the experiment to store model training.\n",
        "* Launch tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbB4AZ63lj2P"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'AerialSegmentation_' + model_name\n",
        "print('Experiment name: %s' % experiment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBV1k4iJHz-Z"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "if train:\n",
        "  #%load_ext tensorboard\n",
        "  %reload_ext tensorboard\n",
        "  %tensorboard --logdir={experiment_name}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZM4ILBwtDaV"
      },
      "source": [
        "###**Launch training**\n",
        "* When train = True, this cells trains the network. \\\\\n",
        "* The loss function used for training the Cross Entropy Loss. The model is trained and optimized only based on the segmentation prediction. \\\\\n",
        "* Validation is run at the end of each epoch and the model with best IoU and Dice score is saved as best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIHmSLBPQ_Qt"
      },
      "outputs": [],
      "source": [
        "if train:\n",
        "\n",
        "  cross_entropy = nn.CrossEntropyLoss()\n",
        "  model = model.to(device)\n",
        "  learning_rate = 0.001\n",
        "\n",
        "  # define Adam optimizer\n",
        "  optimizer = torch.optim.Adam(params=model.parameters(), lr= learning_rate)\n",
        "\n",
        "  #Initialize list to store loss values\n",
        "  loss_list = []\n",
        "\n",
        "  # define summary writer\n",
        "  writer = SummaryWriter(experiment_name)\n",
        "\n",
        "  # initialize iteration number\n",
        "  n_iter = 0\n",
        "\n",
        "  # define best validation value\n",
        "  best_val_dice = 0\n",
        "  best_val_iou = 0\n",
        "\n",
        "  #Lists to store dice and iou scores\n",
        "  micro_dice_list = []\n",
        "  micro_iou_list = []\n",
        "  macro_dice_list = []\n",
        "  macro_iou_list = []\n",
        "\n",
        "  # number of epoch\n",
        "  n_epoch = 30\n",
        "  total_batches = len(trainset)//batch_size\n",
        "\n",
        "  #Progress bar for epochs\n",
        "  tqdm_epochs = tqdm_notebook(total=n_epoch, desc='Epochs')\n",
        "\n",
        "  for cur_epoch in range(n_epoch):\n",
        "      # plot current epoch\n",
        "      writer.add_scalar(\"epoch\", cur_epoch, n_iter)\n",
        "\n",
        "      # Progress bar for batches\n",
        "      tqdm_batches = tqdm_notebook(total= total_batches, desc=f'Epoch {cur_epoch}')\n",
        "\n",
        "      for inp, mask in trainloader:\n",
        "          # move batch to gpu\n",
        "          inp = inp.to(device)\n",
        "          mask = mask.to(device)\n",
        "\n",
        "          # reset gradients\n",
        "          optimizer.zero_grad()\n",
        "          # get output\n",
        "          outmask = model(inp)\n",
        "\n",
        "          # compute loss\n",
        "          loss = nn.CrossEntropyLoss().to(device)\n",
        "          loss = loss(outmask, mask.long())\n",
        "          loss.backward()\n",
        "\n",
        "          # update weights\n",
        "          optimizer.step()\n",
        "\n",
        "          #Plot\n",
        "          writer.add_scalar(\"Loss\",loss.item(), n_iter)\n",
        "\n",
        "          #Update progress bar\n",
        "          tqdm_batches.update(1)\n",
        "          n_iter += 1\n",
        "\n",
        "      loss_list += [loss.item()]\n",
        "\n",
        "      # At the end, validate model\n",
        "      # Validate the model with IoU, Dice, micro and macro accuracy\n",
        "      cur_iou_micro, cur_dice_micro, cur_iou_macro, cur_dice_macro = validate(model, valloader, device)\n",
        "\n",
        "      #Add current scores to the lists\n",
        "      micro_dice_list += [cur_dice_micro]\n",
        "      micro_iou_list += [cur_iou_micro]\n",
        "      macro_dice_list += [cur_dice_macro]\n",
        "      macro_iou_list += [cur_iou_macro]\n",
        "\n",
        "      # plot validation scores\n",
        "      writer.add_scalar(\"Dice\", cur_dice_micro, cur_epoch)\n",
        "      writer.add_scalar(\"IoU\", cur_iou_micro, cur_epoch)\n",
        "\n",
        "      #Save current data to external file\n",
        "      save_data(plots_folder, experiment_name)\n",
        "\n",
        "      # Check if it is the best model so far\n",
        "      if (best_val_dice is None or cur_dice_micro >= best_val_dice) and (best_val_iou is None or cur_iou_micro >= best_val_iou):\n",
        "          # define new best val\n",
        "          best_val_dice = cur_dice_micro\n",
        "          best_val_iou = cur_iou_micro\n",
        "\n",
        "          # save current model as best\n",
        "          torch.save({\n",
        "              'model': model.state_dict(),\n",
        "              'opt': optimizer.state_dict(),\n",
        "              'epoch': cur_epoch\n",
        "          }, f'{drive_dir}/Models/' + experiment_name + '_best.pth')\n",
        "\n",
        "      # save last model\n",
        "      torch.save({\n",
        "          'model': model.state_dict(),\n",
        "          'opt': optimizer.state_dict(),\n",
        "          'epoch': cur_epoch\n",
        "      },f'{drive_dir}/Models/' + experiment_name + '_last.pth')\n",
        "\n",
        "      tqdm_batches.close()\n",
        "      tqdm_epochs.update(1)\n",
        "\n",
        "  tqdm_epochs.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-saO2HS6AyM"
      },
      "source": [
        "###**Compare training history**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poEJHFRT9L3t"
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to store training history of each dataset\n",
        "models_dict = {encoder1 : dict(), encoder2: dict(), encoder2 +'f': dict(), encoder2 + 'a': dict(), encoder1 + 'dl': dict(), encoder2 + 'fdl': dict()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJi1flxmbboF"
      },
      "outputs": [],
      "source": [
        "#Import traning history of all datasets\n",
        "for key in models_dict.keys():\n",
        "    pkl_file = 'AerialSegmentation_' + key + '_data.pkl'\n",
        "    with open(drive_dir + plots_folder + pkl_file, 'rb') as file:\n",
        "      models_dict[key] = pkl.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM28jMx5-b1K"
      },
      "outputs": [],
      "source": [
        "#Visualize keys of a dictionary\n",
        "models_dict[encoder1].keys()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Labels for legend\n",
        "model_labels = ['UNet-MobileNet',\n",
        "          'UNet-EfficientNet',\n",
        "          'UNet-EfficientNet-f',\n",
        "          'UNet-EfficientNet-a',\n",
        "          'DL-MobileNet',\n",
        "          'DL-EfficientNet-f']"
      ],
      "metadata": {
        "id": "SFmrcC10vepc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plrbLm6z95O0"
      },
      "outputs": [],
      "source": [
        "#Loss function for six models\n",
        "loss_fig = plt.figure(figsize = (10,5))\n",
        "for key in models_dict.keys():\n",
        "  data = models_dict[key]['loss']\n",
        "  plt.plot(data, label = key)\n",
        "  print('Minimum loss of ' + key + ': %.3f' % (np.min(data)))\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(range(30), range(1,31))\n",
        "plt.title('Cross-Entropy Loss')\n",
        "plt.grid(alpha = 0.5)\n",
        "plt.legend(model_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwRR_280_IoC"
      },
      "outputs": [],
      "source": [
        "#Micro dice score for six models\n",
        "fig = plt.figure(figsize = (10,5))\n",
        "for key in models_dict.keys():\n",
        "  data = models_dict[key]['dice_micro']\n",
        "  plt.plot(data, label = key)\n",
        "  print('Max Micro Dice Score of ' + key + ': %.3f' % np.max(data) + ' at epoch: %i' % (np.argmax(data)+1))\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice score')\n",
        "plt.xticks(range(30), range(1,31))\n",
        "plt.title('Micro Dice score')\n",
        "plt.grid(alpha = 0.5)\n",
        "plt.legend(model_labels,loc = 'lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58sGk2HY_Ich"
      },
      "outputs": [],
      "source": [
        "#Macro Dice score for six models\n",
        "fig2 = plt.figure(figsize = (10,5))\n",
        "for key in models_dict.keys():\n",
        "  data = models_dict[key]['dice_macro']\n",
        "  plt.plot(data, label = key)\n",
        "  print('Max Macro Dice Score of ' + key + ': %.3f' % np.max(data) + ' at epoch: %i' % (np.argmax(data)+1))\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice score')\n",
        "plt.xticks(range(30), range(1,31))\n",
        "plt.title('Macro Dice score')\n",
        "plt.grid(alpha = 0.5)\n",
        "plt.legend(model_labels, loc = 'lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERGj1unS_IG8"
      },
      "outputs": [],
      "source": [
        "#Micro IoU score for six models\n",
        "fig3 = plt.figure(figsize = (10,5))\n",
        "for key in models_dict.keys():\n",
        "  data = models_dict[key]['iou_micro']\n",
        "  plt.plot(data, label = key)\n",
        "  print('Max Micro Iou Score of ' + key + ': %.3f' % np.max(data) + ' at epoch: %i' % (np.argmax(data)+1))\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU score')\n",
        "plt.xticks(range(30), range(1,31))\n",
        "plt.title('Micro IoU score')\n",
        "plt.grid(alpha = 0.5)\n",
        "plt.legend(model_labels,loc = 'lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJpCxLLb_M0O"
      },
      "outputs": [],
      "source": [
        "#Macro IoU score for six models\n",
        "fig4 = plt.figure(figsize = (10,5))\n",
        "for key in models_dict.keys():\n",
        "  data = models_dict[key]['iou_macro']\n",
        "  plt.plot(data, label = key)\n",
        "  print('Max Macro Iou Score of ' + key + ': %.3f' % np.max(data) + ' at epoch: %i' % (np.argmax(data)+1))\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('IoU score')\n",
        "plt.xticks(range(30), range(1,31))\n",
        "plt.title('Macro IoU score')\n",
        "plt.grid(alpha = 0.5)\n",
        "plt.legend(model_labels, loc = 'lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FEnLY6VlkNK"
      },
      "source": [
        "# Test model on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section the accuracy scores are computed for the test set and store in a common dataframe."
      ],
      "metadata": {
        "id": "meJKVKbF_d4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNbGXUz8YX2s"
      },
      "outputs": [],
      "source": [
        "if create_new_df:\n",
        "  #Create a dataframe to store models values\n",
        "  test_metrics = pd.DataFrame(columns = ['model','iou_micro', 'dice_micro', 'iou_macro', 'dice_macro','iou_class', 'dice_class'])\n",
        "\n",
        "else:\n",
        "  #Load metrics dataset\n",
        "  test_metrics = pd.read_csv(drive_dir + '/test_metrics.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajHh6rgO5Idl"
      },
      "outputs": [],
      "source": [
        "# Import a model to evaluate\n",
        "import_model = True\n",
        "encoder = encoder1\n",
        "\n",
        "if import_model:\n",
        "  model_structure, model_name = define_model(encoder, unet = True)\n",
        "  model = load_model(model_structure, model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL2l_E6h-LKE"
      },
      "source": [
        "**Compute metrics for test set** \\\\\n",
        "The validation function is also used to validate the model with the test set. return_labels = True to compute confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model and add it to the dataframe if it is not present yet\n",
        "if model_name not in test_metrics['model'].tolist():\n",
        "  row_val = pd.DataFrame([model_name] + list(validate(model, testloader, device, per_class = True))).T\n",
        "  row_val.columns = test_metrics.columns\n",
        "  test_metrics = pd.concat([test_metrics, row_val], ignore_index = True)\n",
        "\n",
        "  #Export the dataframe\n",
        "  test_metrics.to_csv(drive_dir + '/test_metrics.csv', index = False)"
      ],
      "metadata": {
        "id": "k1zIYO6iJmT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDKmoV6qErAy"
      },
      "outputs": [],
      "source": [
        "#Accuracy scores for all models\n",
        "for idx in test_metrics.index:\n",
        "  row = test_metrics.iloc[idx]\n",
        "  print('Results for experiment: %s' % row['model'])\n",
        "  print('Micro dice score on test set: %.3f' % row['dice_micro'])\n",
        "  print('Macro dice score on test set: %.3f' % row['dice_macro'])\n",
        "  print('Micro iou score on test set: %.3f' % row['iou_micro'])\n",
        "  print('Macro iou score on test set: %.3f \\n' % row['iou_macro'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Labels for barplots\n",
        "model_labels2 = ['DL-MobileNet',\n",
        "                  'UNet-MobileNet',\n",
        "                  'UNet-EfficientNet',\n",
        "                  'UNet-EfficientNet-f',\n",
        "                  'UNet-EfficientNet-a',\n",
        "                  'DL-EfficientNet-f']\n",
        "\n",
        "#Function to make a barplot for a per-class variable\n",
        "def barplot(data, column, variable_name):\n",
        "  #Number of bins (one per class)\n",
        "  r = np.arange(23)\n",
        "  width = 0.12\n",
        "\n",
        "  #Colors to plot each model\n",
        "  colors = ['purple', 'blue', 'orange', 'green', 'red',  'yellow']\n",
        "\n",
        "  plt.figure(figsize = (15,6))\n",
        "  for i in range(len(data['model'])):\n",
        "    data_col = data[column][i]\n",
        "    plt.bar(r + i*width, data_col,\n",
        "            width = width, color = colors[i],\n",
        "            edgecolor = 'black',\n",
        "            label=data['model'][i])\n",
        "\n",
        "  plt.xlabel(\"Class\", fontsize = 12)\n",
        "  plt.ylabel(variable_name)\n",
        "  plt.title(variable_name + \" per class\")\n",
        "\n",
        "  plt.ylim(0,1.01)\n",
        "  plt.yticks(np.arange(0,1.1,0.1))\n",
        "  plt.xticks(r + ((len(data)*width)-width)/2, labels.name[:-1], rotation = 90)\n",
        "  plt.legend(model_labels2)\n",
        "  plt.grid(alpha = 0.5)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "H8PEwI5jSEqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuYfozFliBJl"
      },
      "outputs": [],
      "source": [
        "#--IoU per class--\n",
        "barplot(test_metrics, 'iou_class', 'IoU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFukE4HflFT-"
      },
      "outputs": [],
      "source": [
        "#--Dice score per class--\n",
        "barplot(test_metrics, 'dice_class', 'Dice score')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaGxoY1J-yZN"
      },
      "source": [
        "**Visualize test results** \\\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIEFqoGHx18S"
      },
      "outputs": [],
      "source": [
        "#This function is used to convert the 2d mask into rgb mask using the labels-colors .csv file\n",
        "def convert_mask_to_rgb(mask, colors):\n",
        "\n",
        "  mask_classes = np.unique(mask)\n",
        "  rgb_mask_or = np.array([mask, mask, mask])\n",
        "  rgb_mask = np.array([mask, mask, mask])\n",
        "  rgb_mask_or = np.transpose(rgb_mask_or, (1,2,0))\n",
        "  rgb_mask = np.transpose(rgb_mask, (1,2,0))\n",
        "\n",
        "  for cl in mask_classes:\n",
        "    rgb_colors = [colors['r'].iloc[cl], colors['g'].iloc[cl], colors['b'].iloc[cl]]\n",
        "    rgb_mask = np.where(rgb_mask_or == cl, rgb_colors, rgb_mask)\n",
        "\n",
        "  return rgb_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4OBSD7u8C6O"
      },
      "outputs": [],
      "source": [
        "if plot_predictions:\n",
        "  i = 0\n",
        "\n",
        "  for img, msk in testloader:\n",
        "    #Set model to evaluation mode\n",
        "    model.eval()\n",
        "    #Predict output mask and convert output to np.array\n",
        "    outmask = model(img.to(device))\n",
        "    segm_mask, _ = output_to_mask(outmask)\n",
        "\n",
        "    #Convert 2D mask to RGB mask, increase size and restore original aspect of the image\n",
        "    colored_mask = convert_mask_to_rgb(segm_mask, labels)\n",
        "    colored_mask = np.array(Image.fromarray(colored_mask.astype(np.uint8)).resize((768, 512), resample=Image.NEAREST))\n",
        "\n",
        "    #Open original image (not normalized) and rgb mask (not normalized or resized)\n",
        "    or_img = np.array(Image.open(test_dir['Image'].iloc[i]).resize((768, 512), resample=Image.NEAREST))\n",
        "    or_mask = np.array(Image.open(test_dir['RGB Mask'].iloc[i]).resize((768, 512), resample=Image.NEAREST))\n",
        "\n",
        "    #Plot original image, rgb mask and predicted rgb mask\n",
        "    plt.subplots(1, 3, figsize = (20,5))\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(or_img)\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(or_mask)\n",
        "    plt.title('Original Mask')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(colored_mask)\n",
        "    plt.title('Predicted Mask')\n",
        "\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    if i == 3:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG5Egb8wORHP"
      },
      "source": [
        "**Function to count predictions made for each class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "og27BL2mOcqf"
      },
      "outputs": [],
      "source": [
        "#This function works per image\n",
        "def predicted_classes(mask, pred_mask):\n",
        "  #Create a 2D array to store predictions for each class\n",
        "  predictions = np.zeros((23,23))\n",
        "  #Store predictions made for each label\n",
        "  for label in range(23):\n",
        "    #Find true location of the label inside the ground truth image\n",
        "    idx = np.argwhere(mask == label)\n",
        "    idx_mask = []\n",
        "    for elem in idx:\n",
        "      row, col = elem\n",
        "      pixel_value = pred_mask[row,col]\n",
        "      idx_mask.append(pixel_value)\n",
        "    #Count predicted classes for that label and store in the 2D array\n",
        "    predictions[label] = np.bincount(idx_mask, minlength = 23)\n",
        "\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lc5FbduvWKxb"
      },
      "outputs": [],
      "source": [
        "#Array to store predicted classes for each label in the whole dataset\n",
        "total_predictions = np.zeros((23,23))\n",
        "\n",
        "for img, msk in testloader:\n",
        "  #Set model to evaluation mode\n",
        "  model.eval()\n",
        "  #Predict output mask and convert output to np.array\n",
        "  outmask = model(img.to(device))\n",
        "  segm_mask, _ = output_to_mask(outmask)\n",
        "\n",
        "  #Add predictions for each image to the total predictions\n",
        "  msk = np.array(msk.squeeze(0))\n",
        "  total_predictions += predicted_classes(msk, segm_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJOynxIS0cUQ"
      },
      "outputs": [],
      "source": [
        "#Divide the predictions made for each class by the total number of class pixels/predictions\n",
        "for i in range(total_predictions.shape[0]):\n",
        "  total_predictions[i] /= np.sum(total_predictions[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEum_1G9WukI"
      },
      "outputs": [],
      "source": [
        "#Visualize predictions matrix\n",
        "plt.figure(figsize = (6,6))\n",
        "im = plt.imshow(total_predictions)\n",
        "\n",
        "plt.xticks(range(23), labels['name'][:-1], rotation = 90)\n",
        "plt.yticks(range(23), labels['name'][:-1])\n",
        "\n",
        "#Highlight 'paved_area' class\n",
        "plt.axvline(1, c = 'r')\n",
        "\n",
        "#Highlight 'paved_area' class\n",
        "plt.axvline(3, c = 'pink')\n",
        "\n",
        "\n",
        "plt.colorbar(im, label = 'Fraction', fraction = 0.046, pad = 0.04)\n",
        "plt.clim(0,1)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "\n",
        "plt.title('Fraction of true vs. predicted classes (DL-EfficientNet-f)')\n",
        "plt.grid(alpha = 0.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkJNPbgd7HZi"
      },
      "outputs": [],
      "source": [
        "#Classes that are predicted as paved area or grass in more than 10% of cases\n",
        "labels_above_10 = np.argwhere(((total_predictions[:,1] >= 0.1)|(total_predictions[:,3] >= 0.1)))[:,0]\n",
        "print(f'Classes predicted as paved areas or grass more than 10% of the time are: {list(labels_above_10)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5SF3xNhm6aK"
      },
      "source": [
        "#Land drone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is used for findind available landing area and a target landing spot."
      ],
      "metadata": {
        "id": "qh9nhJvRAeXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MZp7NHPINjG"
      },
      "outputs": [],
      "source": [
        "# Import model to use (set to DL-MobileNet)\n",
        "import_model = True\n",
        "encoder = encoder1\n",
        "\n",
        "if import_model:\n",
        "  model_structure, model_name = define_model(encoder, unet = False)\n",
        "  model = load_model(model_structure, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6jYCE_8XG3M"
      },
      "outputs": [],
      "source": [
        "#--Define transformations for the encoder--\n",
        "transform = transform_resize(encoder)\n",
        "\n",
        "#--Normalize--\n",
        "# Data is normalized for the pretrained model\n",
        "normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPpisTMcZxK5"
      },
      "outputs": [],
      "source": [
        "#Function to find possible landing areas on certain classes (+50% margin)\n",
        "#Arguments:\n",
        "#mask = Segmented mask to inspect\n",
        "#drone_size = Size of the drone to land\n",
        "#label_list = Classes where drone can land\n",
        "def convolution(mask, drone_size = (40,40), label_list = [1,3]):\n",
        "  h = int(drone_size[0] + 0.5*drone_size[0])\n",
        "  w = int(drone_size[1] + 0.5*drone_size[1])\n",
        "  kernel = np.ones((h,w))\n",
        "  result = np.zeros(mask.shape)\n",
        "  for lab in label_list:\n",
        "    binary_mask = np.where(mask == lab, 1, 0)\n",
        "    conv_res = convolve2d(binary_mask, kernel, mode = 'same')\n",
        "    result = np.where(conv_res == h*w, 1, result)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Randomly choose a pair of coordinates from the available landing area\n",
        "def random_point_selection(array):\n",
        "  target_idx = np.argwhere(array == 1)\n",
        "  rand_idx = np.random.randint(0, len(target_idx))\n",
        "  target_spot = target_idx[rand_idx]\n",
        "  return target_spot"
      ],
      "metadata": {
        "id": "hlp-KzKLY_dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose the middle pair of coordinates from the available landing area\n",
        "def middle_point_selection(array):\n",
        "    target_idx = np.argwhere(array == 1)\n",
        "    middle_idx = len(target_idx)//2\n",
        "    target_spot = target_idx[middle_idx]\n",
        "    return target_spot"
      ],
      "metadata": {
        "id": "hdDWwu6PV-5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAjkY76ESTDP"
      },
      "outputs": [],
      "source": [
        "#--Function to compute the landing area and landing spot from segmentation result, and to draw a rectangle around the landing spot on the original image and mask\n",
        "#Pass image and masks as PIL image\n",
        "def landing_spot(img, msk, rgb_msk, net, target_classes = [1,3], method ='rp', drone_size = (40, 40)):\n",
        "  #Create a resized version of original image, mask and RGB mask\n",
        "  img_r = Image.fromarray(img).resize((768, 512), resample=Image.NEAREST)\n",
        "  rgb_msk_r = Image.fromarray(rgb_msk).resize((768, 512), resample=Image.NEAREST)\n",
        "  msk_r = Image.fromarray(msk).resize((768, 512), resample=Image.NEAREST)\n",
        "\n",
        "  #Apply transformations and normalization for model\n",
        "  img_n = normalize(image = img)['image']\n",
        "  img_t = transform(image = img_n)['image']\n",
        "\n",
        "  #Set model to evaluation mode and predict output\n",
        "  net.eval()\n",
        "  output = net(img_t.unsqueeze(0))\n",
        "  #Transform output to mask\n",
        "  segm_mask, _ = output_to_mask(output)\n",
        "\n",
        "  #Upsample mask\n",
        "  segm_mask = np.array(Image.fromarray(segm_mask.astype(np.uint8)).resize((768, 512), resample=Image.NEAREST))\n",
        "\n",
        "  #Find possible landing areas in the mask\n",
        "  sample_res = convolution(segm_mask, drone_size, target_classes)\n",
        "\n",
        "  if method == 'rp':\n",
        "    target_y, target_x = random_point_selection(sample_res)\n",
        "\n",
        "  elif method == 'mp':\n",
        "    target_y, target_x = middle_point_selection(sample_res)\n",
        "\n",
        "  #Split drone size in width and height\n",
        "  w, h = drone_size\n",
        "  #Shape of the rectangle = (x0,y0), (x1,y1)\n",
        "  shape = [(target_x - w/2, target_y + h/2), (target_x + w/2, target_y - h/2)]\n",
        "  #Draw rectangle around target spot on original image\n",
        "  img_target = ImageDraw.Draw(img_r)\n",
        "  img_target.rectangle(shape, fill = None, outline ='red', width = 3)\n",
        "\n",
        "  #Draw rectangle on the original RGB mask\n",
        "  segm_target = ImageDraw.Draw(rgb_msk_r)\n",
        "  segm_target.rectangle(shape, fill = None, outline =\"red\", width = 3)\n",
        "\n",
        "  return sample_res, img_r, msk_r, rgb_msk_r, [target_y, target_x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNewnpzzZtqj"
      },
      "outputs": [],
      "source": [
        "#Visualize segmented output in rgb\n",
        "print_label_colors()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#--Drone landing with Random Point Selection--\n",
        "#List to store the ground truth class of the target spot found by Random Point Selection\n",
        "random_target_class = []\n",
        "\n",
        "#Define the test dataset\n",
        "testset = Dataset(test_dir, rgb = True)\n",
        "\n",
        "#Open one image at a time from the test set\n",
        "for i in range(len(testset)):\n",
        "  sample_img, sample_mask, sample_rgb_mask = testset[i]\n",
        "  #Find landing spot\n",
        "  landing_area, target_sample, resized_mask, target_mask, target_spot = landing_spot(sample_img, sample_mask, sample_rgb_mask, model)\n",
        "\n",
        "  #Add ground truth class of the target spot\n",
        "  random_target_class += [np.array(resized_mask)[target_spot[0], target_spot[1]]]\n",
        "\n",
        "  #plot first ten images\n",
        "  if i < 10:\n",
        "    plt.subplots(1,3, figsize = (15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    custom_cmap = ListedColormap(['#FF0000','#7CFC00'])\n",
        "    plt.imshow(target_sample)\n",
        "    im = plt.imshow(landing_area, cmap = custom_cmap, alpha = 0.5)\n",
        "    plt.colorbar(im, ticks = [0,1], fraction = 0.03, pad = 0.04)\n",
        "    plt.title('Possible landing area')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(target_sample)\n",
        "    plt.title(f'Target coordinates: x,y = {target_spot[1],target_spot[0]}')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(target_sample)\n",
        "    plt.imshow(target_mask, alpha = 0.7)\n",
        "    plt.title(f'Target coordinates: x,y = {target_spot[1],target_spot[0]}')\n"
      ],
      "metadata": {
        "id": "lxXLM6meW5Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "middle_target_class = []\n",
        "\n",
        "for i in range(len(testset)):\n",
        "  sample_img, sample_mask, sample_rgb_mask = testset[i]\n",
        "  #Find target spot\n",
        "  landing_area, target_sample, resized_mask, target_mask, target_spot = landing_spot(sample_img, sample_mask, sample_rgb_mask, model, method = 'mp')\n",
        "\n",
        "  #Add true class of the target spot\n",
        "  middle_target_class += [np.array(resized_mask)[target_spot[0], target_spot[1]]]\n",
        "\n",
        "  #Plot first ten images\n",
        "  if i < 10:\n",
        "    plt.subplots(1,3, figsize = (15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(target_sample)\n",
        "    custom_cmap = ListedColormap(['#FF0000','#7CFC00'])\n",
        "    im = plt.imshow(landing_area, cmap = custom_cmap, alpha = 0.5)\n",
        "    plt.colorbar(im, ticks = [0,1], fraction = 0.03, pad = 0.04)\n",
        "    plt.title('Possible landing area')\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(target_sample)\n",
        "    plt.title(f'Target coordinates: x,y = {target_spot[1],target_spot[0]}')\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(target_sample)\n",
        "    plt.imshow(target_mask, alpha = 0.7)\n",
        "    plt.title(f'Target coordinates: x,y = {target_spot[1],target_spot[0]}')"
      ],
      "metadata": {
        "id": "MGQSPm5Fa6Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--Landing on wrong object for random point--\n",
        "wrong_rand = np.sum(np.where((random_target_class != 1)&(random_target_class != 3)))\n",
        "frac_rand = wrong_rand/len(random_target_class)\n",
        "print('Fraction of wrong landing out of 40 with Random Point Selection: %.3f' %frac_rand)\n",
        "\n",
        "#--Landing on wrong object for middle point--\n",
        "wrong_mid = np.sum(np.where((middle_target_class != 1)&(middle_target_class != 3)))\n",
        "frac_mid= wrong_rand/len(middle_target_class)\n",
        "print('Fraction of wrong landing out of 40 with Middle Point Selection: %.3f' %frac_mid)"
      ],
      "metadata": {
        "id": "jFbcP0E9qNCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LEq7pw6nlajs",
        "6GD7PhwVfXT2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}